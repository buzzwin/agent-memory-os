# agent-memory-os

Agent Memory OS is an open-source memory layer for AI agents â€” providing persistent, semantic + episodic memory that spans time, tools, and multi-agent systems.

# ğŸ§  Agent Memory OS

## Overview

Modern LLM agents are smart â€” but forgetful.

They can answer questions, write code, and simulate workflows, but as soon as the session ends, they forget everything. This creates brittle experiences, limits long-term learning, and makes it hard to scale AI assistants in real-world use cases.

**Agent Memory OS** solves this by offering a plug-and-play memory architecture that adds persistent, structured memory to your AI agents â€” across sessions, across tasks, and even across teams of agents.

---

## ğŸš§ The Problem

LLM agents today lack true long-term memory.

- âŒ Agents forget previous conversations or context unless manually re-fed.
- âŒ Developers have to rebuild memory pipelines from scratch for every app.
- âŒ No standard for sharing memory across agents or workflows.
- âŒ Vector search â‰  structured memory with episodic or semantic context.
- âŒ No temporal awareness â€” agents don't "remember what happened when."

This results in fragile systems and poor user experience.

---

## âœ… The Solution

**Agent Memory OS** is a developer-first memory framework for agentic systems.

- ğŸ§© Unified **episodic**, **semantic**, and **temporal** memory
- ğŸ” Works across **LangChain**, **CrewAI**, **LangGraph**, **REST API**, and custom agents
- ğŸ§  Designed for **multi-agent collaboration** with shared context
- ğŸ“š Easily plug into your LLM pipeline via a simple SDK, API, or HTTP
- â±ï¸ Supports time-aware memory recall and timeline reconstruction

---

## ğŸ› ï¸ Who It's For

- AI engineers building assistants, copilots, and autonomous workflows
- Teams using LangGraph, CrewAI, LangChain, or REST APIs
- Developers building apps that need persistent, evolving memory

---

## ğŸ“‹ Implementation Status

### âœ… **Fully Implemented**

#### Core Memory System

- **MemoryManager** - Main interface for memory operations
- **MemoryEntry** - Data model for individual memories
- **MemoryType** - Enum for episodic, semantic, and temporal memory types
- **SQLiteStore** - Persistent storage backend with full CRUD operations
- **Basic embedding generation** - Hash-based embeddings for demo purposes

#### Memory Operations

- âœ… Add memories with metadata and timestamps
- âœ… Search memories by content (text-based LIKE search)
- âœ… Filter memories by type, agent_id, session_id
- âœ… Retrieve episodic memories for specific agents/sessions
- âœ… Get chronological timeline of memories
- âœ… Memory persistence across sessions

#### Utilities

- âœ… Time utilities for timestamp formatting and parsing
- âœ… Embedding utilities with cosine similarity calculations
- âœ… Memory serialization (to_dict/from_dict)

#### Testing & Examples

- âœ… Comprehensive unit tests (9/9 passing)
- âœ… Working demo with CrewAI integration example
- âœ… Memory persistence demonstration

#### LangChain Integration âœ… **COMPLETE**

- âœ… **MemoryChain** - LangChain chain with automatic memory storage and retrieval
- âœ… **MemoryTool** - LangChain tool for agents to store facts and search memories
- âœ… **MemoryCallbackHandler** - Automatic memory storage during chain/agent execution
- âœ… **MemoryAwareAgent** - Wrapper for any LangChain agent with memory capabilities
- âœ… **Complete integration demo** - Working example with all components
- âœ… **Memory persistence** - Memories survive across sessions and agent restarts
- âœ… **Semantic search** - Basic text-based search for relevant memories
- âœ… **Timeline retrieval** - Get chronological history of agent activities

#### LangGraph Integration âœ… **NEW - COMPLETE**

- âœ… **MemoryGraph** - Complete memory-aware LangGraph workflow wrapper
- âœ… **MemoryState** - State class with memory capabilities for LangGraph
- âœ… **MemoryNode** - Node that provides memory operations in workflows
- âœ… **MemoryToolNode** - Tools that can be used in any LangGraph workflow
- âœ… **create_memory_tools** - Helper function to create memory tools
- âœ… **Complete integration demo** - 4 comprehensive demos showing different usage patterns
- âœ… **Memory persistence** - Memories survive across graph executions
- âœ… **Agent-specific memory isolation** - Each agent/workflow has isolated memory
- âœ… **ToolNode compatibility** - Works with latest LangGraph ToolNode API
- âœ… **Dict-based state management** - Maximum compatibility with LangGraph

#### REST API Integration âœ… **NEW - COMPLETE**

- âœ… **FastAPI-based REST API** for remote memory access
- âœ… **Full CRUD**: create, update, delete, search, and list memories
- âœ… **Agent-specific endpoints** and statistics
- âœ… **Health and status endpoints**
- âœ… **Python client library** (`MemoryAPIClient`, `AsyncMemoryAPIClient`)
- âœ… **Comprehensive demo** (`examples/api_demo.py`)
- âœ… **Interactive docs** at `/docs` and `/redoc`

#### Web UI Integration âœ… **NEW - COMPLETE**

- âœ… **Modern web interface** for memory visualization and management
- âœ… **Real-time statistics** and memory type breakdowns
- âœ… **Interactive search and filtering** by type, agent, and importance
- âœ… **Memory detail views** with full metadata
- âœ… **Create and delete memories** directly from the UI
- âœ… **Responsive design** that works on desktop and mobile
- âœ… **Auto-refresh** and live updates
- âœ… **Sample data demo** (`examples/web_ui_demo.py`)

### ğŸš§ **Partially Implemented**

#### Semantic Search

- âœ… **Vector similarity search** with Pinecone integration
- âœ… **Model-based embeddings** using `llama-text-embed-v2` (1024 dimensions)
- âœ… **High-quality semantic search** across all memory types
- âœ… **Fallback text search** for SQLite backend
- âœ… **Cosine similarity** calculations for relevance scoring

#### LangChain Integration

- âš ï¸ **MemoryAwareAgent callback compatibility** - Minor callback handler issue with LLMChain (cosmetic, doesn't affect core functionality)
- âš ï¸ **Deprecation warnings** - Some LangChain APIs are deprecated but still functional

### âŒ **Not Yet Implemented**

#### Advanced Features

- âŒ Vector similarity search using embeddings
- âŒ Integration with proper embedding models (OpenAI, sentence-transformers)
- âŒ Memory compression and summarization
- âŒ Memory importance scoring
- âŒ Automatic memory cleanup/archival
- âŒ Multi-agent memory sharing protocols

#### Integrations

- âŒ Direct CrewAI integration (only example code provided)

#### Storage Backends

- âœ… **Pinecone Integration** - Vector database with semantic search
  - âœ… Model-based embeddings with `llama-text-embed-v2`
  - âœ… 1024-dimensional vectors for high-quality semantic search
  - âœ… Automatic index creation and management
  - âœ… Cross-session memory persistence
  - âœ… Full CRUD operations with metadata
- âœ… **Store Factory** - Adapter pattern for multiple backends
- âœ… **Auto-detection** - Automatically chooses SQLite or Pinecone
- âŒ PostgreSQL backend
- âŒ Redis backend
- âŒ Other vector databases (Weaviate, Qdrant, etc.)clear
- âŒ Cloud storage options

#### Advanced Memory Features

- âŒ Memory relationships and linking
- âŒ Memory versioning and history
- âŒ Memory privacy and access control
- âŒ Memory export/import functionality
- âŒ Memory analytics and insights

---

## ğŸ” MVP Goal

Enable a basic CrewAI, LangChain, LangGraph, or REST API agent to:

- âœ… Remember key facts across sessions
- âœ… Recall specific past interactions (episodic)
- âœ… Retrieve semantically relevant info when prompted (basic text search)
- âœ… Track events across time
- âœ… Access and manage memory remotely via HTTP or Python client

**âœ… MVP COMPLETED** - All core memory functionality is working with LangChain, LangGraph, and REST API integrations!

---

## ğŸ“¦ Project Structure

```
agent-memory-os/
â”œâ”€â”€ agent_memory_sdk/          # Core SDK
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ memory.py              # MemoryManager class
â”‚   â”œâ”€â”€ models.py              # Data models (MemoryEntry, MemoryType)
â”‚   â”œâ”€â”€ store/                 # Storage backends
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_store.py      # Abstract base class
â”‚   â”‚   â”œâ”€â”€ sqlite_store.py    # SQLite storage implementation
â”‚   â”‚   â”œâ”€â”€ pinecone_store.py  # Pinecone vector storage
â”‚   â”‚   â””â”€â”€ store_factory.py   # Store factory for backend selection
â”‚   â”œâ”€â”€ utils/                 # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embedding_utils.py # Embedding generation and similarity
â”‚   â”‚   â””â”€â”€ time_utils.py      # Time formatting utilities
â”‚   â”œâ”€â”€ api/                   # REST API (FastAPI server, client, models)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ server.py          # FastAPI app and endpoints
â”‚   â”‚   â”œâ”€â”€ models.py          # Pydantic models for API
â”‚   â”‚   â”œâ”€â”€ client.py          # Python/async client for API
â”‚   â”‚   â””â”€â”€ static/            # Web UI static files
â”‚   â”‚       â”œâ”€â”€ index.html     # Main web UI page
â”‚   â”‚       â”œâ”€â”€ styles.css     # Web UI styles
â”‚   â”‚       â””â”€â”€ app.js         # Web UI JavaScript
â”‚   â””â”€â”€ integrations/          # Framework integrations
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ langchain/         # LangChain integration
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ memory_chain.py        # MemoryChain class
â”‚       â”‚   â”œâ”€â”€ memory_tool.py         # MemoryTool class
â”‚       â”‚   â”œâ”€â”€ memory_callback.py     # MemoryCallbackHandler
â”‚       â”‚   â””â”€â”€ memory_agent.py        # MemoryAwareAgent wrapper
â”‚       â””â”€â”€ langgraph/         # LangGraph integration
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ memory_graph.py        # MemoryGraph class
â”‚           â”œâ”€â”€ memory_state.py        # MemoryState class
â”‚           â”œâ”€â”€ memory_node.py         # MemoryNode class
â”‚           â””â”€â”€ memory_tool_node.py    # MemoryToolNode class
â”œâ”€â”€ examples/                  # Integration examples
â”‚   â”œâ”€â”€ crewai_memory_demo.py  # CrewAI integration demo
â”‚   â”œâ”€â”€ langchain_memory_demo.py # LangChain integration demo
â”‚   â”œâ”€â”€ langgraph_memory_demo.py # LangGraph integration demo
â”‚   â”œâ”€â”€ api_demo.py            # REST API demo (HTTP, client, async)
â”‚   â””â”€â”€ web_ui_demo.py         # Web UI demo with sample data
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_memory.py         # Comprehensive test suite
â”œâ”€â”€ requirements.txt           # Dependencies
â””â”€â”€ README.md                 # This file
```

---

## ğŸš€ Quick Start

### Installation

```bash
git clone <repository>
cd agent-memory-os
pip install -r requirements.txt
```

### Run the REST API Server

```bash
# Run from the project root directory
python run_api.py --host 127.0.0.1 --port 8000
```

**API Endpoints:**

- ğŸ“š **Docs**: http://127.0.0.1:8000/docs (Interactive API documentation)
- ğŸ” **ReDoc**: http://127.0.0.1:8000/redoc (Alternative API docs)
- â¤ï¸ **Health**: http://127.0.0.1:8000/health (Server status)
- ğŸ¨ **Web UI**: http://127.0.0.1:8000 (Interactive web interface)

**Features:**

- Full CRUD operations for memories
- Semantic search and filtering
- Agent-specific endpoints
- Real-time statistics and health monitoring

### Use the Python Client

```python
from agent_memory_sdk.api import MemoryAPIClient
from agent_memory_sdk.api.models import MemoryCreateRequest
from agent_memory_sdk.models import MemoryType

with MemoryAPIClient("http://localhost:8000") as client:
    req = MemoryCreateRequest(content="Hello", memory_type=MemoryType.SEMANTIC)
    memory = client.create_memory(req)
    print(memory)
```

### Use the Async Python Client

```python
import asyncio
from agent_memory_sdk.api import AsyncMemoryAPIClient
from agent_memory_sdk.api.models import MemoryCreateRequest
from agent_memory_sdk.models import MemoryType

async def main():
    async with AsyncMemoryAPIClient("http://localhost:8000") as client:
        req = MemoryCreateRequest(content="Async hello", memory_type=MemoryType.EPISODIC)
        memory = await client.create_memory(req)
        print(memory)

asyncio.run(main())
```

### Try the REST API Demo

```bash
python examples/api_demo.py
```

### Try the Web UI Demo

```bash
# Run from any directory - the script will automatically find the project root
python examples/web_ui_demo.py
```

This will:

1. **Create sample memory data** with various types and agents
2. **Launch the web UI server** at http://localhost:8000
3. **Open your browser** automatically to the web interface
4. **Show interactive features** like search, filtering, and memory management

**Web UI Features:**

- ğŸ“Š Real-time memory statistics and breakdowns
- ğŸ” Interactive search and filtering by type, agent, and importance
- ğŸ“ Create and delete memories directly from the interface
- ğŸ“± Responsive design for desktop and mobile
- ğŸ”„ Auto-refresh and live updates

### Basic Usage (SDK)

```python
from agent_memory_sdk import MemoryManager, MemoryType

# Initialize memory manager (auto-detects SQLite or Pinecone)
memory_manager = MemoryManager()

# Add memories
memory_manager.add_memory(
    content="User prefers Python programming",
    memory_type=MemoryType.SEMANTIC,
    agent_id="my_agent",
    importance=8.0,
    tags=["preference", "programming"]
)

# Search memories (semantic search with Pinecone, text search with SQLite)
results = memory_manager.search_memory("Python")
```

### Storage Backends

The system supports multiple storage backends:

#### SQLite (Default - Local)

```python
# Local SQLite storage
memory_manager = MemoryManager(store_type="sqlite", db_path="memories.db")
```

#### Pinecone (Cloud - Vector Search)

```bash
# Set environment variables
export PINECONE_API_KEY="your-api-key"
export PINECONE_ENVIRONMENT="your-environment"
```

```python
# Pinecone vector storage with semantic search
memory_manager = MemoryManager(store_type="pinecone", index_name="my-memories")
```

### Try the Pinecone Demo

```bash
# Set your Pinecone credentials
export PINECONE_API_KEY="your-api-key"
export PINECONE_ENVIRONMENT="your-environment"

# Run the demo
python examples/pinecone_memory_demo.py
```

**Features demonstrated:**

- Model-based embeddings with `llama-text-embed-v2`
- High-quality semantic search
- Memory persistence across sessions
- Comparison between SQLite and Pinecone backends

### LangChain Integration

```python
from agent_memory_sdk import MemoryChain, MemoryManager
from langchain_community.llms import OpenAI

# Initialize memory manager
memory_manager = MemoryManager()

# Create memory-aware chain
memory_chain = MemoryChain(
    memory_manager=memory_manager,
    llm=OpenAI(),
    agent_id="my_agent"
)

# Use with memory persistence
result = memory_chain.invoke({"input": "What do you remember about me?"})
print(result["output"])
```

### LangGraph Integration

```python
from agent_memory_sdk import MemoryGraph, MemoryManager
from langgraph.graph import StateGraph, END

# Initialize memory manager
memory_manager = MemoryManager()

# Create memory-aware graph
memory_graph = MemoryGraph(
    memory_manager=memory_manager,
    agent_id="my_agent",
    session_id="session_1"
)

# Create a simple graph
graph = memory_graph.create_graph()

# Add a processing node
def process_input(state):
    input_text = state.get("input", "")
    memory_graph.memory_manager.add_memory(
        content=f"Processed: {input_text}",
        memory_type=MemoryType.EPISODIC,
        agent_id=memory_graph.agent_id,
        session_id=memory_graph.session_id
    )
    return {"output": f"Processed: {input_text}"}

graph.add_node("process", process_input)
graph.set_entry_point("process")
graph.add_edge("process", END)

# Compile and run
compiled_graph = graph.compile()
result = compiled_graph.invoke({"input": "Hello, this is my first memory!"})
```

### Memory Tools in LangGraph

```python
from agent_memory_sdk import create_memory_tools, MemoryManager
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, AIMessage
import uuid

# Create memory tools
memory_tools = create_memory_tools(
    memory_manager=MemoryManager(),
    agent_id="my_agent"
)

# Create tool node
tool_node = ToolNode(memory_tools)

# Use with proper message format
tool_call = {
    "name": "store_memory",
    "args": {"content": "I learned something new", "memory_type": "semantic"},
    "id": str(uuid.uuid4()),
    "type": "tool_call"
}

state = {
    "messages": [
        HumanMessage(content="Store a memory"),
        AIMessage(content="", tool_calls=[tool_call])
    ]
}

result = tool_node.invoke(state)
```

### Run Demos

```bash
# All demos can be run from any directory - they'll automatically find the project root

# Core memory demo (SQLite backend)
python examples/crewai_memory_demo.py

# LangChain integration demo
python examples/langchain_memory_demo.py

# LangGraph integration demo
python examples/langgraph_memory_demo.py

# REST API demo (tests HTTP client and async client)
python examples/api_demo.py

# Web UI demo (creates sample data and launches web interface)
python examples/web_ui_demo.py

# Pinecone integration demo (requires Pinecone credentials)
python examples/pinecone_memory_demo.py
```

**Demo Features:**

- ğŸ§  **Core Demo**: Basic memory operations with SQLite
- ğŸ”— **LangChain Demo**: Memory-aware chains, tools, and agents
- ğŸ“Š **LangGraph Demo**: Memory integration with workflows and state
- ğŸŒ **API Demo**: HTTP client, async client, and REST endpoints
- ğŸ¨ **Web UI Demo**: Interactive web interface with sample data
- ğŸŒ² **Pinecone Demo**: Vector search with semantic embeddings

### Debug and Maintenance Tools

```bash
# Debug Pinecone configuration
python debug_pinecone.py

# Debug Pinecone search functionality
python debug_pinecone_search.py

# Clean up old Pinecone indexes
python cleanup_pinecone.py
```

### Run Tests

```bash
python -m pytest tests/ -v
```

### Troubleshooting

**Common Issues:**

1. **"run_api.py not found" error**

   - âœ… **Fixed**: All demo scripts now automatically find the project root
   - Run demos from any directory: `python examples/web_ui_demo.py`

2. **Pinecone connection errors**

   - Set environment variables: `export PINECONE_API_KEY="your-key"`
   - Use supported environment: `export PINECONE_ENVIRONMENT="gcp-starter"`
   - Run debug script: `python debug_pinecone.py`

3. **API server startup errors**

   - âœ… **Fixed**: MemoryManager initialization now properly handles store types
   - Ensure you're in the project root: `python run_api.py --host 127.0.0.1 --port 8000`

4. **Memory search returning 0 results**
   - Check if memories were saved successfully
   - Run debug script: `python debug_pinecone_search.py`
   - Clean up old indexes: `python cleanup_pinecone.py`

---

## ğŸ”— Status

ğŸš€ **MVP Complete + Full Framework Integration + Vector Search** â€” Core memory system is working with SQLite and Pinecone storage, comprehensive LangChain, LangGraph, and REST API integrations, persistent memory across sessions, and high-quality semantic search capabilities.

**Current Capabilities:**

- âœ… Persistent memory storage and retrieval
- âœ… LangChain integration with chains, tools, and agents
- âœ… LangGraph integration with workflows, state management, and tools
- âœ… REST API for remote memory access (HTTP, Python, async)
- âœ… Web UI for memory visualization and management
- âœ… Memory-aware responses with context
- âœ… Timeline and semantic search
- âœ… Cross-session memory persistence
- âœ… Agent-specific memory isolation
- âœ… **Vector similarity search** with Pinecone integration
- âœ… **Model-based embeddings** for high-quality semantic search
- âœ… **Robust demo scripts** that work from any directory
- âœ… **Comprehensive debugging tools** for troubleshooting

**Next Milestones:**

1. Add CrewAI integration
2. Implement memory compression and summarization
3. Add memory importance scoring

---

## ğŸ“¬ Stay in the Loop

Want to contribute or test it early? Reach out or open an issue!
