Metadata-Version: 2.4
Name: agent-memory-os
Version: 0.1.0
Summary: A comprehensive memory layer for AI agents providing persistent, semantic + episodic memory
Home-page: https://github.com/your-org/agent-memory-os
Author: Agent Memory OS Contributors
Author-email: contributors@agent-memory-os.dev
Project-URL: Bug Tracker, https://github.com/your-org/agent-memory-os/issues
Project-URL: Documentation, https://github.com/your-org/agent-memory-os#readme
Project-URL: Source Code, https://github.com/your-org/agent-memory-os
Keywords: ai,agents,memory,langchain,langgraph,pinecone,postgresql,vector-search,semantic-memory,episodic-memory,machine-learning,artificial-intelligence
Platform: any
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
Classifier: Framework :: FastAPI
Classifier: Framework :: LangChain
Classifier: Framework :: LangGraph
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pydantic>=2.0.0
Requires-Dist: numpy>=1.21.0
Requires-Dist: langchain>=0.1.0
Requires-Dist: langchain-community>=0.0.10
Requires-Dist: langchain-core>=0.1.0
Requires-Dist: langgraph>=0.5.0
Requires-Dist: fastapi>=0.104.0
Requires-Dist: uvicorn[standard]>=0.24.0
Requires-Dist: aiohttp>=3.8.0
Requires-Dist: requests>=2.28.0
Requires-Dist: pinecone>=7.0.0
Requires-Dist: psycopg2-binary>=2.9.0
Requires-Dist: mcp>=1.0.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: pytest>=7.0.0
Requires-Dist: pytest-asyncio>=0.21.0
Requires-Dist: pytest-cov>=4.0.0
Requires-Dist: black>=23.0.0
Requires-Dist: flake8>=6.0.0
Requires-Dist: mypy>=1.0.0
Requires-Dist: bandit>=1.7.0
Requires-Dist: safety>=2.0.0
Requires-Dist: pydocstyle>=6.0.0
Requires-Dist: build>=0.10.0
Requires-Dist: twine>=4.0.0
Requires-Dist: wheel>=0.40.0
Provides-Extra: langchain
Requires-Dist: langchain>=0.1.0; extra == "langchain"
Requires-Dist: langchain-community>=0.0.10; extra == "langchain"
Requires-Dist: langchain-core>=0.1.0; extra == "langchain"
Provides-Extra: langgraph
Requires-Dist: langgraph>=0.0.20; extra == "langgraph"
Provides-Extra: pinecone
Requires-Dist: pinecone>=7.0.0; extra == "pinecone"
Provides-Extra: postgresql
Requires-Dist: psycopg2-binary>=2.9.0; extra == "postgresql"
Provides-Extra: api
Requires-Dist: fastapi>=0.100.0; extra == "api"
Requires-Dist: uvicorn[standard]>=0.20.0; extra == "api"
Requires-Dist: httpx>=0.24.0; extra == "api"
Provides-Extra: mcp
Requires-Dist: mcp>=1.0.0; extra == "mcp"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Requires-Dist: langchain>=0.1.0; extra == "dev"
Requires-Dist: langchain-community>=0.0.10; extra == "dev"
Requires-Dist: langchain-core>=0.1.0; extra == "dev"
Requires-Dist: langgraph>=0.0.20; extra == "dev"
Requires-Dist: pinecone>=7.0.0; extra == "dev"
Requires-Dist: psycopg2-binary>=2.9.0; extra == "dev"
Requires-Dist: fastapi>=0.100.0; extra == "dev"
Requires-Dist: uvicorn[standard]>=0.20.0; extra == "dev"
Requires-Dist: httpx>=0.24.0; extra == "dev"
Requires-Dist: mcp>=1.0.0; extra == "dev"
Provides-Extra: all
Requires-Dist: langchain>=0.1.0; extra == "all"
Requires-Dist: langchain-community>=0.0.10; extra == "all"
Requires-Dist: langchain-core>=0.1.0; extra == "all"
Requires-Dist: langgraph>=0.0.20; extra == "all"
Requires-Dist: pinecone>=7.0.0; extra == "all"
Requires-Dist: psycopg2-binary>=2.9.0; extra == "all"
Requires-Dist: fastapi>=0.100.0; extra == "all"
Requires-Dist: uvicorn[standard]>=0.20.0; extra == "all"
Requires-Dist: httpx>=0.24.0; extra == "all"
Requires-Dist: mcp>=1.0.0; extra == "all"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license-file
Dynamic: platform
Dynamic: project-url
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# agent-memory-os

Agent Memory OS is an open-source memory layer for AI agents â€” providing persistent, semantic + episodic memory that spans time, tools, and multi-agent systems.

# ğŸ§  Agent Memory OS

## Overview

Modern LLM agents are smart â€” but forgetful.

They can answer questions, write code, and simulate workflows, but as soon as the session ends, they forget everything. This creates brittle experiences, limits long-term learning, and makes it hard to scale AI assistants in real-world use cases.

**Agent Memory OS** solves this by offering a plug-and-play memory architecture that adds persistent, structured memory to your AI agents â€” across sessions, across tasks, and even across teams of agents.

---

## ğŸš§ The Problem

LLM agents today lack true long-term memory.

- âŒ Agents forget previous conversations or context unless manually re-fed.
- âŒ Developers have to rebuild memory pipelines from scratch for every app.
- âŒ No standard for sharing memory across agents or workflows.
- âŒ Vector search â‰  structured memory with episodic or semantic context.
- âŒ No temporal awareness â€” agents don't "remember what happened when."

This results in fragile systems and poor user experience.

---

## âœ… The Solution

**Agent Memory OS** is a developer-first memory framework for agentic systems.

- ğŸ§© Unified **episodic**, **semantic**, and **temporal** memory
- ğŸ” Works across **LangChain**, **CrewAI**, **LangGraph**, **REST API**, and custom agents
- ğŸ§  Designed for **multi-agent collaboration** with shared context
- ğŸ“š Easily plug into your LLM pipeline via a simple SDK, API, or HTTP
- â±ï¸ Supports time-aware memory recall and timeline reconstruction

---

## ğŸ› ï¸ Who It's For

- AI engineers building assistants, copilots, and autonomous workflows
- Teams using LangGraph, CrewAI, LangChain, or REST APIs
- Developers building apps that need persistent, evolving memory

---

## ğŸ“‹ Implementation Status

### âœ… **Fully Implemented**

#### Core Memory System

- **MemoryManager** - Main interface for memory operations
- **MemoryEntry** - Data model for individual memories
- **MemoryType** - Enum for episodic, semantic, and temporal memory types
- **SQLiteStore** - Persistent storage backend with full CRUD operations
- **Basic embedding generation** - Hash-based embeddings for demo purposes

#### Memory Operations

- âœ… Add memories with metadata and timestamps
- âœ… Search memories by content (text-based LIKE search)
- âœ… Filter memories by type, agent_id, session_id
- âœ… Retrieve episodic memories for specific agents/sessions
- âœ… Get chronological timeline of memories
- âœ… Memory persistence across sessions

#### Utilities

- âœ… Time utilities for timestamp formatting and parsing
- âœ… Embedding utilities with cosine similarity calculations
- âœ… Memory serialization (to_dict/from_dict)

#### Testing & Examples

- âœ… Comprehensive unit tests (9/9 passing)
- âœ… Working demo with CrewAI integration example
- âœ… Memory persistence demonstration

#### LangChain Integration âœ… **COMPLETE**

- âœ… **MemoryChain** - LangChain chain with automatic memory storage and retrieval
- âœ… **MemoryTool** - LangChain tool for agents to store facts and search memories
- âœ… **MemoryCallbackHandler** - Automatic memory storage during chain/agent execution
- âœ… **MemoryAwareAgent** - Wrapper for any LangChain agent with memory capabilities
- âœ… **Complete integration demo** - Working example with all components
- âœ… **Memory persistence** - Memories survive across sessions and agent restarts
- âœ… **Semantic search** - Basic text-based search for relevant memories
- âœ… **Timeline retrieval** - Get chronological history of agent activities

#### LangGraph Integration âœ… **NEW - COMPLETE**

- âœ… **MemoryGraph** - Complete memory-aware LangGraph workflow wrapper
- âœ… **MemoryState** - State class with memory capabilities for LangGraph
- âœ… **MemoryNode** - Node that provides memory operations in workflows
- âœ… **MemoryToolNode** - Tools that can be used in any LangGraph workflow
- âœ… **create_memory_tools** - Helper function to create memory tools
- âœ… **Complete integration demo** - 4 comprehensive demos showing different usage patterns
- âœ… **Memory persistence** - Memories survive across graph executions
- âœ… **Agent-specific memory isolation** - Each agent/workflow has isolated memory
- âœ… **ToolNode compatibility** - Works with latest LangGraph ToolNode API
- âœ… **Dict-based state management** - Maximum compatibility with LangGraph

#### REST API Integration âœ… **NEW - COMPLETE**

- âœ… **FastAPI-based REST API** for remote memory access
- âœ… **Full CRUD**: create, update, delete, search, and list memories
- âœ… **Agent-specific endpoints** and statistics
- âœ… **Health and status endpoints**
- âœ… **Python client library** (`MemoryAPIClient`, `AsyncMemoryAPIClient`)
- âœ… **Comprehensive demo** (`examples/api_demo.py`)
- âœ… **Interactive docs** at `/docs` and `/redoc`

#### Web UI Integration âœ… **NEW - COMPLETE**

- âœ… **Modern web interface** for memory visualization and management
- âœ… **Real-time statistics** and memory type breakdowns
- âœ… **Interactive search and filtering** by type, agent, and importance
- âœ… **Memory detail views** with full metadata
- âœ… **Create and delete memories** directly from the UI
- âœ… **Responsive design** that works on desktop and mobile
- âœ… **Auto-refresh** and live updates
- âœ… **Sample data demo** (`examples/web_ui_demo.py`)

#### MCP (Model Context Protocol) Integration âœ… **NEW - COMPLETE**

- âœ… **Complete MCP server implementation** for Claude Desktop integration
- âœ… **Memory tools**: search, create, update, delete, and get statistics
- âœ… **Memory resources**: individual memories and summary overview
- âœ… **Multiple storage backends**: SQLite, Pinecone, and PostgreSQL support
- âœ… **CLI interface**: `agent-memory-mcp` command with full configuration options
- âœ… **stdio and HTTP modes**: Flexible deployment for different MCP clients
- âœ… **Configuration files**: Ready-to-use configs for Claude Desktop
- âœ… **Comprehensive demo** (`examples/mcp_server_demo.py`)

### ğŸš§ **Partially Implemented**

#### Semantic Search

- âœ… **Vector similarity search** with Pinecone integration
- âœ… **Model-based embeddings** using `llama-text-embed-v2` (1024 dimensions)
- âœ… **High-quality semantic search** across all memory types
- âœ… **Fallback text search** for SQLite backend
- âœ… **Cosine similarity** calculations for relevance scoring

#### LangChain Integration

- âš ï¸ **MemoryAwareAgent callback compatibility** - Minor callback handler issue with LLMChain (cosmetic, doesn't affect core functionality)
- âš ï¸ **Deprecation warnings** - Some LangChain APIs are deprecated but still functional

### âŒ **Not Yet Implemented**

#### Advanced Features

- âŒ Vector similarity search using embeddings
- âŒ Integration with proper embedding models (OpenAI, sentence-transformers)
- âŒ Memory compression and summarization
- âŒ Memory importance scoring
- âŒ Automatic memory cleanup/archival
- âŒ Multi-agent memory sharing protocols

#### Integrations

- âŒ Direct CrewAI integration (only example code provided)

#### Storage Backends

- âœ… **Pinecone Integration** - Vector database with semantic search
  - âœ… Model-based embeddings with `llama-text-embed-v2`
  - âœ… 1024-dimensional vectors for high-quality semantic search
  - âœ… Automatic index creation and management
  - âœ… Cross-session memory persistence
  - âœ… Full CRUD operations with metadata
- âœ… **PostgreSQL Integration** - Production-ready relational database
  - âœ… Full-text search with PostgreSQL's tsvector/tsquery
  - âœ… JSONB support for flexible metadata storage
  - âœ… ACID compliance and transaction support
  - âœ… High-performance indexing and querying
  - âœ… Scalable for large memory datasets
- âœ… **Store Factory** - Adapter pattern for multiple backends
- âœ… **Auto-detection** - Automatically chooses SQLite, PostgreSQL, or Pinecone
- âŒ Redis backend
- âŒ Other vector databases (Weaviate, Qdrant, etc.)
- âŒ Cloud storage options

#### Advanced Memory Features

- âŒ Memory relationships and linking
- âŒ Memory versioning and history
- âŒ Memory privacy and access control
- âŒ Memory export/import functionality
- âŒ Memory analytics and insights

---

## ğŸ” MVP Goal

Enable a basic CrewAI, LangChain, LangGraph, or REST API agent to:

- âœ… Remember key facts across sessions
- âœ… Recall specific past interactions (episodic)
- âœ… Retrieve semantically relevant info when prompted (basic text search)
- âœ… Track events across time
- âœ… Access and manage memory remotely via HTTP or Python client

**âœ… MVP COMPLETED** - All core memory functionality is working with LangChain, LangGraph, and REST API integrations!

---

## ğŸ“¦ Project Structure

```
agent-memory-os/
â”œâ”€â”€ agent_memory_sdk/          # Core SDK
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ memory.py              # MemoryManager class
â”‚   â”œâ”€â”€ models.py              # Data models (MemoryEntry, MemoryType)
â”‚   â”œâ”€â”€ store/                 # Storage backends
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_store.py      # Abstract base class
â”‚   â”‚   â”œâ”€â”€ sqlite_store.py    # SQLite storage implementation
â”‚   â”‚   â”œâ”€â”€ pinecone_store.py  # Pinecone vector storage
â”‚   â”‚   â””â”€â”€ store_factory.py   # Store factory for backend selection
â”‚   â”œâ”€â”€ utils/                 # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embedding_utils.py # Embedding generation and similarity
â”‚   â”‚   â””â”€â”€ time_utils.py      # Time formatting utilities
â”‚   â”œâ”€â”€ api/                   # REST API (FastAPI server, client, models)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ server.py          # FastAPI app and endpoints
â”‚   â”‚   â”œâ”€â”€ models.py          # Pydantic models for API
â”‚   â”‚   â”œâ”€â”€ client.py          # Python/async client for API
â”‚   â”‚   â””â”€â”€ static/            # Web UI static files
â”‚   â”‚       â”œâ”€â”€ index.html     # Main web UI page
â”‚   â”‚       â”œâ”€â”€ styles.css     # Web UI styles
â”‚   â”‚       â””â”€â”€ app.js         # Web UI JavaScript
â”‚   â””â”€â”€ integrations/          # Framework integrations
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ langchain/         # LangChain integration
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ memory_chain.py        # MemoryChain class
â”‚       â”‚   â”œâ”€â”€ memory_tool.py         # MemoryTool class
â”‚       â”‚   â”œâ”€â”€ memory_callback.py     # MemoryCallbackHandler
â”‚       â”‚   â””â”€â”€ memory_agent.py        # MemoryAwareAgent wrapper
â”‚       â”œâ”€â”€ langgraph/         # LangGraph integration
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ memory_graph.py        # MemoryGraph class
â”‚       â”‚   â”œâ”€â”€ memory_state.py        # MemoryState class
â”‚       â”‚   â”œâ”€â”€ memory_node.py         # MemoryNode class
â”‚       â”‚   â””â”€â”€ memory_tool_node.py    # MemoryToolNode class
â”‚       â””â”€â”€ mcp/               # MCP (Model Context Protocol) integration
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ memory_mcp_server.py   # MCP server implementation
â”œâ”€â”€ examples/                  # Integration examples
â”‚   â”œâ”€â”€ crewai_memory_demo.py  # CrewAI integration demo
â”‚   â”œâ”€â”€ langchain_memory_demo.py # LangChain integration demo
â”‚   â”œâ”€â”€ langgraph_memory_demo.py # LangGraph integration demo
â”‚   â”œâ”€â”€ mcp_server_demo.py     # MCP server demo
â”‚   â”œâ”€â”€ api_demo.py            # REST API demo (HTTP, client, async)
â”‚   â””â”€â”€ web_ui_demo.py         # Web UI demo with sample data
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_memory.py         # Comprehensive test suite
â”œâ”€â”€ requirements.txt           # Dependencies
â””â”€â”€ README.md                 # This file
```

---

## ğŸš€ Quick Start

### Installation

```bash
git clone <repository>
cd agent-memory-os
pip install -r requirements.txt
```

### Run the REST API Server

```bash
# Run from the project root directory
python run_api.py --host 127.0.0.1 --port 8000
```

**API Endpoints:**

- ğŸ“š **Docs**: http://127.0.0.1:8000/docs (Interactive API documentation)
- ğŸ” **ReDoc**: http://127.0.0.1:8000/redoc (Alternative API docs)
- â¤ï¸ **Health**: http://127.0.0.1:8000/health (Server status)
- ğŸ¨ **Web UI**: http://127.0.0.1:8000 (Interactive web interface)

**Features:**

- Full CRUD operations for memories
- Semantic search and filtering
- Agent-specific endpoints
- Real-time statistics and health monitoring

### Use the Python Client

```python
from agent_memory_sdk.api import MemoryAPIClient
from agent_memory_sdk.api.models import MemoryCreateRequest
from agent_memory_sdk.models import MemoryType

with MemoryAPIClient("http://localhost:8000") as client:
    req = MemoryCreateRequest(content="Hello", memory_type=MemoryType.SEMANTIC)
    memory = client.create_memory(req)
    print(memory)
```

### Use the Async Python Client

```python
import asyncio
from agent_memory_sdk.api import AsyncMemoryAPIClient
from agent_memory_sdk.api.models import MemoryCreateRequest
from agent_memory_sdk.models import MemoryType

async def main():
    async with AsyncMemoryAPIClient("http://localhost:8000") as client:
        req = MemoryCreateRequest(content="Async hello", memory_type=MemoryType.EPISODIC)
        memory = await client.create_memory(req)
        print(memory)

asyncio.run(main())
```

### Try the REST API Demo

```bash
python examples/api_demo.py
```

### Try the Web UI Demo

```bash
# Run from any directory - the script will automatically find the project root
python examples/web_ui_demo.py
```

This will:

1. **Create sample memory data** with various types and agents
2. **Launch the web UI server** at http://localhost:8000
3. **Open your browser** automatically to the web interface
4. **Show interactive features** like search, filtering, and memory management

**Web UI Features:**

- ğŸ“Š Real-time memory statistics and breakdowns
- ğŸ” Interactive search and filtering by type, agent, and importance
- ğŸ“ Create and delete memories directly from the interface
- ğŸ“± Responsive design for desktop and mobile
- ğŸ”„ Auto-refresh and live updates

### Basic Usage (SDK)

```python
from agent_memory_sdk import MemoryManager, MemoryType

# Initialize memory manager (auto-detects SQLite or Pinecone)
memory_manager = MemoryManager()

# Add memories
memory_manager.add_memory(
    content="User prefers Python programming",
    memory_type=MemoryType.SEMANTIC,
    agent_id="my_agent",
    importance=8.0,
    tags=["preference", "programming"]
)

# Search memories (semantic search with Pinecone, text search with SQLite)
results = memory_manager.search_memory("Python")
```

### Storage Backends

The system supports multiple storage backends:

#### SQLite (Default - Local)

```python
# Local SQLite storage
memory_manager = MemoryManager(store_type="sqlite", db_path="memories.db")
```

#### Pinecone (Cloud - Vector Search)

```bash
# Set environment variables
export PINECONE_API_KEY="your-api-key"
export PINECONE_ENVIRONMENT="your-environment"
```

```python
# Pinecone vector storage with semantic search
memory_manager = MemoryManager(store_type="pinecone", index_name="my-memories")
```

#### PostgreSQL (Production - Relational Database)

```bash
# Set environment variables
export POSTGRESQL_HOST="localhost"
export POSTGRESQL_PORT="5432"
export POSTGRESQL_DATABASE="agent_memory"
export POSTGRESQL_USER="postgres"
export POSTGRESQL_PASSWORD="your_password"

# OR use connection string
export POSTGRESQL_CONNECTION_STRING="postgresql://user:pass@host:port/db"
```

```python
# PostgreSQL storage with full-text search
memory_manager = MemoryManager(store_type="postgresql")

# Or with explicit connection parameters
memory_manager = MemoryManager(
    store_type="postgresql",
    host="localhost",
    port="5432",
    database="agent_memory",
    user="postgres",
    password="your_password"
)
```

### Try the Pinecone Demo

```bash
# Set your Pinecone credentials
export PINECONE_API_KEY="your-api-key"
export PINECONE_ENVIRONMENT="your-environment"

# Run the demo
python examples/pinecone_memory_demo.py
```

**Features demonstrated:**

- Model-based embeddings with `llama-text-embed-v2`
- High-quality semantic search
- Memory persistence across sessions
- Comparison between SQLite and Pinecone backends

### LangChain Integration

```python
from agent_memory_sdk import MemoryChain, MemoryManager
from langchain_community.llms import OpenAI

# Initialize memory manager
memory_manager = MemoryManager()

# Create memory-aware chain
memory_chain = MemoryChain(
    memory_manager=memory_manager,
    llm=OpenAI(),
    agent_id="my_agent"
)

# Use with memory persistence
result = memory_chain.invoke({"input": "What do you remember about me?"})
print(result["output"])
```

### LangGraph Integration

```python
from agent_memory_sdk import MemoryGraph, MemoryManager
from langgraph.graph import StateGraph, END

# Initialize memory manager
memory_manager = MemoryManager()

# Create memory-aware graph
memory_graph = MemoryGraph(
    memory_manager=memory_manager,
    agent_id="my_agent",
    session_id="session_1"
)

# Create a simple graph
graph = memory_graph.create_graph()

# Add a processing node
def process_input(state):
    input_text = state.get("input", "")
    memory_graph.memory_manager.add_memory(
        content=f"Processed: {input_text}",
        memory_type=MemoryType.EPISODIC,
        agent_id=memory_graph.agent_id,
        session_id=memory_graph.session_id
    )
    return {"output": f"Processed: {input_text}"}

graph.add_node("process", process_input)
graph.set_entry_point("process")
graph.add_edge("process", END)

# Compile and run
compiled_graph = graph.compile()
result = compiled_graph.invoke({"input": "Hello, this is my first memory!"})
```

### Memory Tools in LangGraph

```python
from agent_memory_sdk import create_memory_tools, MemoryManager
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, AIMessage
import uuid

# Create memory tools
memory_tools = create_memory_tools(
    memory_manager=MemoryManager(),
    agent_id="my_agent"
)

# Create tool node
tool_node = ToolNode(memory_tools)

# Use with proper message format
tool_call = {
    "name": "store_memory",
    "args": {"content": "I learned something new", "memory_type": "semantic"},
    "id": str(uuid.uuid4()),
    "type": "tool_call"
}

state = {
    "messages": [
        HumanMessage(content="Store a memory"),
        AIMessage(content="", tool_calls=[tool_call])
    ]
}

result = tool_node.invoke(state)
```

### MCP (Model Context Protocol) Integration

Agent Memory OS provides a complete MCP server implementation that allows AI assistants like Claude Desktop to access and manage memories through the standardized Model Context Protocol.

#### Quick Start with Claude Desktop

1. **Install the MCP server:**

```bash
pip install agent-memory-os[mcp]
```

2. **Add to Claude Desktop configuration:**

   Copy the configuration from `mcp-server-config.json` to your Claude Desktop config:

   ```json
   {
     "mcpServers": {
       "agent-memory-os": {
         "command": "agent-memory-mcp",
         "args": ["--stdio"],
         "env": {
           "STORE_TYPE": "sqlite",
           "DB_PATH": "agent_memory.db"
         }
       }
     }
   }
   ```

3. **Restart Claude Desktop** and start using memory capabilities!

#### Available MCP Tools

The MCP server provides these tools to AI assistants:

- **`search_memories`** - Search for memories using semantic search and filters
- **`create_memory`** - Create new memory entries with metadata
- **`get_memory_stats`** - Get statistics about stored memories
- **`delete_memory`** - Delete specific memories by ID
- **`update_memory`** - Update existing memory content and metadata

#### Available MCP Resources

- **`memory://*`** - Individual memory resources with full metadata
- **`memory://summary`** - Overview of all stored memories and statistics

#### CLI Usage

```bash
# Run in stdio mode (for Claude Desktop and other MCP clients)
agent-memory-mcp --stdio

# Use different storage backends
agent-memory-mcp --stdio --store-type pinecone --index-name my-memories
agent-memory-mcp --stdio --store-type postgresql --connection-string "postgresql://user:pass@localhost:5432/memories"
```

#### Advanced Configuration

For different storage backends, use the advanced configuration:

```json
{
  "mcpServers": {
    "agent-memory-os-pinecone": {
      "command": "agent-memory-mcp",
      "args": [
        "--stdio",
        "--store-type",
        "pinecone",
        "--index-name",
        "agent-memory-os"
      ],
      "env": {
        "PINECONE_API_KEY": "your-pinecone-api-key-here",
        "PINECONE_ENVIRONMENT": "your-pinecone-environment-here"
      }
    },
    "agent-memory-os-postgresql": {
      "command": "agent-memory-mcp",
      "args": ["--stdio", "--store-type", "postgresql"],
      "env": {
        "POSTGRESQL_CONNECTION_STRING": "postgresql://user:password@localhost:5432/agent_memory"
      }
    }
  }
}
```

#### Try the MCP Demo

```bash
# Run the MCP server demo
python examples/mcp_server_demo.py

# Run in stdio mode for Claude Desktop
python examples/mcp_server_demo.py --stdio
```

**MCP Demo Features:**

- ğŸ§  **Memory Management**: Create, search, and manage memories through MCP
- ğŸ”— **Claude Desktop Integration**: Works seamlessly with Claude Desktop
- ğŸ“Š **Multiple Storage Backends**: SQLite, Pinecone, and PostgreSQL support
- ğŸŒ **HTTP and stdio modes**: Flexible deployment options
- ğŸ› ï¸ **Rich Tool Set**: Complete memory operations through MCP tools

### Run Demos

```bash
# All demos can be run from any directory - they'll automatically find the project root

# Core memory demo (SQLite backend)
python examples/crewai_memory_demo.py

# LangChain integration demo
python examples/langchain_memory_demo.py

# LangGraph integration demo
python examples/langgraph_memory_demo.py

# MCP server demo (for Claude Desktop integration)
python examples/mcp_server_demo.py

# REST API demo (tests HTTP client and async client)
python examples/api_demo.py

# Web UI demo (creates sample data and launches web interface)
python examples/web_ui_demo.py

# Pinecone integration demo (requires Pinecone credentials)
python examples/pinecone_memory_demo.py

# PostgreSQL integration demo (requires PostgreSQL server)
python examples/postgresql_memory_demo.py
```

**Demo Features:**

- ğŸ§  **Core Demo**: Basic memory operations with SQLite
- ğŸ”— **LangChain Demo**: Memory-aware chains, tools, and agents
- ğŸ“Š **LangGraph Demo**: Memory integration with workflows and state
- ğŸ”Œ **MCP Demo**: Claude Desktop integration with memory tools
- ğŸŒ **API Demo**: HTTP client, async client, and REST endpoints
- ğŸ¨ **Web UI Demo**: Interactive web interface with sample data
- ğŸŒ² **Pinecone Demo**: Vector search with semantic embeddings
- ğŸ˜ **PostgreSQL Demo**: Full-text search with relational database

### Debug and Maintenance Tools

```bash
# Debug Pinecone configuration
python debug_pinecone.py

# Debug Pinecone search functionality
python debug_pinecone_search.py

# Clean up old Pinecone indexes
python cleanup_pinecone.py
```

### Run Tests

```bash
python -m pytest tests/ -v
```

### Troubleshooting

**Common Issues:**

1. **"run_api.py not found" error**

   - âœ… **Fixed**: All demo scripts now automatically find the project root
   - Run demos from any directory: `python examples/web_ui_demo.py`

2. **Pinecone connection errors**

   - Set environment variables: `export PINECONE_API_KEY="your-key"`
   - Use supported environment: `export PINECONE_ENVIRONMENT="gcp-starter"`
   - Run debug script: `python debug_pinecone.py`

3. **PostgreSQL connection errors**

   - Install driver: `pip install psycopg2-binary`
   - Set environment variables: `export POSTGRESQL_HOST="localhost"`
   - Create database: `createdb agent_memory`
   - Check connection: `psql -h localhost -U postgres -d agent_memory`

4. **API server startup errors**

   - âœ… **Fixed**: MemoryManager initialization now properly handles store types
   - Ensure you're in the project root: `python run_api.py --host 127.0.0.1 --port 8000`

5. **Memory search returning 0 results**
   - Check if memories were saved successfully
   - Run debug script: `python debug_pinecone_search.py`
   - Clean up old indexes: `python cleanup_pinecone.py`

---

## ğŸ”— Status

ğŸš€ **MVP Complete + Full Framework Integration + Vector Search** â€” Core memory system is working with SQLite and Pinecone storage, comprehensive LangChain, LangGraph, and REST API integrations, persistent memory across sessions, and high-quality semantic search capabilities.

**Current Capabilities:**

- âœ… Persistent memory storage and retrieval
- âœ… LangChain integration with chains, tools, and agents
- âœ… LangGraph integration with workflows, state management, and tools
- âœ… MCP integration for Claude Desktop and other AI assistants
- âœ… REST API for remote memory access (HTTP, Python, async)
- âœ… Web UI for memory visualization and management
- âœ… Memory-aware responses with context
- âœ… Timeline and semantic search
- âœ… Cross-session memory persistence
- âœ… Agent-specific memory isolation
- âœ… **Vector similarity search** with Pinecone integration
- âœ… **Model-based embeddings** for high-quality semantic search
- âœ… **Robust demo scripts** that work from any directory
- âœ… **Comprehensive debugging tools** for troubleshooting

**Next Milestones:**

1. Add CrewAI integration
2. Implement memory compression and summarization
3. Add memory importance scoring

---

## ğŸ“¬ Stay in the Loop

Want to contribute or test it early? Reach out or open an issue!
